{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMljxMHdHtCFeAH5zbC6l1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhananjai14/LLM_tutorials/blob/main/Vector_Database.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Database and Integration with LangChain\n",
        "\n",
        "**What is vector Database?**\n",
        "\n",
        "Vector Database is a specialized type of database optimized for storing and querying high-dimensional vector data. Vector data typically consists of numerical representations of unstructured data. These vectors capture various features or characteristics of the data they represent.\n",
        "\n",
        "These high-dimensional vectors are especially when derived from complex deep learning models. For instance, an image represented by a neural network might be turned into a vector with hundreds or thousands of dimensions. For example\n",
        "1. In the research paper \"Attention is All You Need,\" which introduced the Transformer model, the vector size of a word/token is 512.\n",
        "2. Advanced GPT models like GPT-3 and GPT-4 developed by OpenAI, the vector dimension of a word/token is 12,288.\n",
        "\n",
        "\n",
        "**Why Vector Databases are used?**\n",
        "\n",
        "1. Efficient Similarity Searches: Traditional databases are not optimized for high-dimensional similarity searches. Vector databases use specialized indexing techniques (e.g., KD-Trees, Annoy, HNSW) to efficiently search and retrieve similar vectors.\n",
        "\n",
        "2. Performance: Vector databases offer high-performance querying capabilities, often using in-memory storage and optimized data structures.\n",
        "\n",
        "\n",
        "**Common use cases**\n",
        "\n",
        "1. Recommendation Systems: By representing users and items as vectors, recommendation systems can find the most relevant items for a user based on vector similarity.\n",
        "\n",
        "2. Image and Video Search: Vectors can represent visual features of images and videos, allowing for efficient content-based retrieval.\n",
        "\n",
        "3. Natural Language Processing: Text documents, sentences, and words can be converted into vectors using embeddings (e.g., Word2Vec, BERT), enabling semantic search and text classification.\n",
        "\n",
        "**Examples of Vector Databases**\n",
        "\n",
        "1. Chroma DB (Local DB)\n",
        "2. FAISS (Facebook AI Similarity Search) (Local DB)\n",
        "3. Pinecone (Cloud based)\n",
        "4. MongDB (Cloud Based)\n",
        "\n"
      ],
      "metadata": {
        "id": "nEihuZoB5_Kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChromaDB\n",
        "\n",
        "Official website: https://docs.trychroma.com/\n",
        "\n",
        "Documentation: https://docs.trychroma.com/getting-started\n",
        "\n",
        "The flow of notebook is as follows:\n",
        "* Step 1: Download the dataset and extract the text file.  \n",
        "* Step 2: Convert the data into the embeddings and store into the Chroma DB.\n",
        "* Step 3: Using LLM make the chains to perform QA on the docs."
      ],
      "metadata": {
        "id": "1kgDUMD8_UGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install langchain-community langchain-openai chromadb langchain langchain-chroma openai tiktoken -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QLJQjWJ_gSH",
        "outputId": "14630cd4-9c10-402c-9001-8b8d58441433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n"
      ],
      "metadata": {
        "id": "e5nv1FZqOgtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the Dataset"
      ],
      "metadata": {
        "id": "mSMY0sRaOXix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset to be store int the DB\n",
        "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip\n",
        "!unzip -q new_articles.zip -d new_articles"
      ],
      "metadata": {
        "id": "usyRdOTNCK-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "# from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n"
      ],
      "metadata": {
        "id": "EeFVUCXt_UAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the document\n",
        "loader = DirectoryLoader('./new_articles', glob='./*.txt', loader_cls=TextLoader)\n",
        "documents = loader.load()\n",
        "\n",
        "# split it into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "len(texts)\n",
        "\n"
      ],
      "metadata": {
        "id": "UQABAQln_T97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad379cd-948c-4793-ec28-fd04b9da0c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "233"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting to Embeddings and store to Chroma dB"
      ],
      "metadata": {
        "id": "eKDgYAK1J59q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the openAI embedding function\n",
        "embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
        "persist_directory = 'dB'\n",
        "# load it into Chroma\n",
        "vectordb = Chroma.from_documents(documents=texts,\n",
        "                                 embedding=embeddings,\n",
        "                                 persist_directory=persist_directory)\n",
        "\n"
      ],
      "metadata": {
        "id": "panB8CwM_T6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dB\n",
        "vectordb=Chroma(persist_directory='dB', embedding_function=embeddings)"
      ],
      "metadata": {
        "id": "k421EWxz_T4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing semantic search\n",
        "\n",
        "query = \"How much money does microsoft raised?\"\n",
        "docs = vectordb.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "DG_qh9dZ_T1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b640272b-13b3-44cf-f775-98e0e1ee3fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "April 28, 2023\n",
            "\n",
            "VC firms including Sequoia Capital, Andreessen Horowitz, Thrive and K2 Global are picking up new shares, according to documents seen by TechCrunch. A source tells us Founders Fund is also investing. Altogether the VCs have put in just over $300 million at a valuation of $27 billion to $29 billion. This is separate to a big investment from Microsoft announced earlier this year, a person familiar with the development told TechCrunch, which closed in January. The size of Microsoft’s investment is believed to be around $10 billion, a figure we confirmed with our source.\n",
            "\n",
            "April 25, 2023\n",
            "\n",
            "Called ChatGPT Business, OpenAI describes the forthcoming offering as “for professionals who need more control over their data as well as enterprises seeking to manage their end users.”\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing semantic search\n",
        "retriver = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
        "docs = retriver.invoke(query)\n",
        "print(docs)"
      ],
      "metadata": {
        "id": "enJtxZ7e_Tyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016b902b-dfde-4334-e9a2-6e8adc95f979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'new_articles/05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt'}, page_content='April 28, 2023\\n\\nVC firms including Sequoia Capital, Andreessen Horowitz, Thrive and K2 Global are picking up new shares, according to documents seen by TechCrunch. A source tells us Founders Fund is also investing. Altogether the VCs have put in just over $300 million at a valuation of $27 billion to $29 billion. This is separate to a big investment from Microsoft announced earlier this year, a person familiar with the development told TechCrunch, which closed in January. The size of Microsoft’s investment is believed to be around $10 billion, a figure we confirmed with our source.\\n\\nApril 25, 2023\\n\\nCalled ChatGPT Business, OpenAI describes the forthcoming offering as “for professionals who need more control over their data as well as enterprises seeking to manage their end users.”'), Document(metadata={'source': 'new_articles/05-07-3one4-capital-driven-by-contrarian-bets-raises-200-million-new-fund.txt'}, page_content='Partners of 3one4 Capital, a venture capital firm in India, recently went on a road show to raise a new fund. Within two and a half months, at the height of the worsening global economy, they had secured $200 million. It’s the fourth marquee fund for the Bengaluru-headquartered fund, whose portfolio includes four unicorn startups.\\n\\nThe fund, sixth overall for 3one4 Capital, was oversubscribed to $250 million but the firm is accepting only $200 million to keep itself lean and disciplined, said Pranav Pai, co-founder and partner at 3one4 Capital. The firm’s decision to limit the fund size is emblematic of its strategic choices, which have set it apart from other Indian venture firms.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating response using LLM"
      ],
      "metadata": {
        "id": "-9VRWIi6KGHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "# Creating Prompt\n",
        "system_prompt = (\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise. \\n\\n {context}\")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_prompt),(\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Initializing LLM\n",
        "llm = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Creating chains\n",
        "question_answer_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
        "qa_chain = create_retrieval_chain(retriever=retriver, combine_docs_chain=question_answer_chain)\n",
        "\n",
        "# generating response\n",
        "response = qa_chain.invoke({\"input\": \"How much money did Microsoft raise?\"})\n",
        "print(response[\"answer\"])\n"
      ],
      "metadata": {
        "id": "87VALFxD_Tvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b754598-7e4b-4e3c-c2a1-a183330c2c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "System: Microsoft raised $10 billion in a big investment announced earlier this year.\n"
          ]
        }
      ]
    }
  ]
}